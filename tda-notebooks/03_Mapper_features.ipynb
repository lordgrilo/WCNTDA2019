{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topological feature map\n",
    "Reference: https://royalsocietypublishing.org/doi/full/10.1098/rsif.2017.0734"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn import datasets\n",
    "import pandas as pd\n",
    "try:\n",
    "    import umap\n",
    "except ImportError:\n",
    "    print(\"This example requires the UMAP library. You can install it with the command `!pip install umap-learn`\")\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kmapper as km\n",
    "from kmapper.plotlyviz import plotlyviz\n",
    "from kmapper.plotlyviz import *\n",
    "import plotly.graph_objs as go\n",
    "import ipywidgets as ipw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "data_dir = '../data/epi-ts/'\n",
    "ts = os.listdir(data_dir);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {}\n",
    "epi = []\n",
    "t = []\n",
    "ids = []\n",
    "count = 0;\n",
    "labels = []\n",
    "for i,x in enumerate(sorted(ts)[:3]): \n",
    "    #I'm just using the first three diseases here, you can probably do better \n",
    "    data[x] = pd.read_csv(data_dir+x, skiprows=2,na_values='-',dtype=np.float64);\n",
    "    labels.extend([x.split('_')[0],i]*data[x].shape[1])\n",
    "    filled = data[x].fillna(0);\n",
    "    for col in filled.columns[2:]:\n",
    "        ids.extend([count]*data[x].shape[0]);\n",
    "        epi.extend(filled[col]);\n",
    "        t.extend(range(data[x].shape[0]));\n",
    "        count+=1;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tsfresh as tsf\n",
    "from tsfresh.feature_extraction.extraction import extract_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reshape the timeseries in a format that tsfresh understands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdf = pd.DataFrame(np.array([ids,t,epi]).T, columns=['id','t','epi'])\n",
    "rdf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = extract_features(rdf,column_id='id', column_sort='t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.replace([np.inf, -np.inf, np.nan], 0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.drop(['epi__abs_energy'],axis=1,inplace=True) #this is just because this feature produces errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "mapper = km.KeplerMapper(verbose=0)\n",
    "import umap\n",
    "lens = mapper.fit_transform(np.array(test_df.values).T, projection=umap.UMAP(n_neighbors=10,\n",
    "                                                        min_dist=0.5,\n",
    "                                                        n_components=2,\n",
    "                                                        metric='euclidean',\n",
    "                                                        random_state=int(time.time())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(lens[:,0], lens[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the simplicial complex  \n",
    "scomplex = mapper.map(lens, test_df.values.T,\n",
    "                      clusterer=sklearn.cluster.KMeans(n_clusters=2),#eps=0.5, min_samples=2),\n",
    "                      coverer=km.Cover(20, 0.8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_function = lens[:, 1]-lens[:, 1].min()\n",
    "plotlyviz(scomplex, \n",
    "          title='Mapper graph of digits dataset',\n",
    "          color_function=color_function, \n",
    "          color_function_name='Distance to y-min', \n",
    "          node_linecolor='rgb(100,100,100)',\n",
    "          bgcolor='rgb(240,240,240)',\n",
    "          width=620, height=620,\n",
    "          summary_height=350,\n",
    "          summary_left=10,\n",
    "          hist_left=25,\n",
    "          hist_right=10,\n",
    "          graph_data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_function = lens[:, 1]-lens[:, 1].min()\n",
    "plotlyviz(scomplex, \n",
    "          title='Mapper graph of digits dataset',\n",
    "          color_function=color_function, \n",
    "          color_function_name='Distance to y-min', \n",
    "          node_linecolor='rgb(100,100,100)',\n",
    "          bgcolor='rgb(240,240,240)',\n",
    "          width=620, height=620,\n",
    "          summary_height=350,\n",
    "          summary_left=10,\n",
    "          hist_left=25,\n",
    "          hist_right=10,\n",
    "          member_textbox_width=500,\n",
    "          dashboard=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's save the result in html format and visualize it in interactive mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_n = test_df.columns\n",
    "# Tooltips with the membership labels for every cluster member\n",
    "html =  mapper.visualize(scomplex,\n",
    "                          path_html=\"keplermapper_feature_custom_tooltips.html\",\n",
    "                          custom_tooltips=labels_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kmapper import jupyter # Creates custom CSS full-size Jupyter screen\n",
    "jupyter.display(path_html=\"keplermapper_feature_custom_tooltips.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's label the diseases and see whether we can tell them apart from the features.  \n",
    "You can assign the disease labels to the state data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_labels = [0]*60\n",
    "classification_labels.extend([1]*60)\n",
    "classification_labels.extend([2]*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And try to exploit the properties of the mapper graph to choose features wisely. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = km.to_networkx(scomplex);\n",
    "import networkx as nx\n",
    "GC = g.subgraph(list(nx.connected_components(g))[0]);\n",
    "ecc = nx.eccentricity(GC)\n",
    "# bet = nx.betweenness_centrality(GC)\n",
    "# deg = dict(nx.degree(GC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_score = []\n",
    "random_score = []\n",
    "\n",
    "\n",
    "for topk in range(1,15):\n",
    "\n",
    "    s = [(k, ecc[k]) for k in sorted(ecc, key=ecc.get, reverse=False)]\n",
    "#     s = [(k, bet[k]) for k in sorted(bet, key=bet.get, reverse=False)]\n",
    "#     s = [(k, deg[k]) for k in sorted(deg, key=deg.get, reverse=False)]\n",
    "    selected_columns = []\n",
    "    mem = nx.get_node_attributes(GC,'membership')\n",
    "    cols = test_df.columns\n",
    "    for k in range(topk):\n",
    "        selected_columns.append(cols[mem[s[k][0]]][0]) \n",
    "\n",
    "    y = classification_labels    \n",
    "    X = test_df[selected_columns]\n",
    "\n",
    "\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "    from sklearn.preprocessing import MinMaxScaler\n",
    "    scaler = MinMaxScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    logreg = LogisticRegression()\n",
    "    logreg.fit(X_train, y_train)\n",
    "    print('Accuracy of Logistic regression classifier on training set: {:.2f}'\n",
    "         .format(logreg.score(X_train, y_train)))\n",
    "    print('Accuracy of Logistic regression classifier on test set: {:.2f}'\n",
    "         .format(logreg.score(X_test, y_test)))\n",
    "    real_score.append((logreg.score(X_train, y_train),logreg.score(X_test, y_test)))\n",
    "    iterations = 20\n",
    "    res = []\n",
    "    for it in range(iterations):\n",
    "\n",
    "        random_cols = np.random.choice(cols,len(selected_columns))\n",
    "        X_random = test_df[random_cols]\n",
    "\n",
    "        from sklearn.model_selection import train_test_split\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X_random, y,random_state=int(time.time()))\n",
    "        from sklearn.preprocessing import MinMaxScaler\n",
    "        scaler = MinMaxScaler()\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "        from sklearn.linear_model import LogisticRegression\n",
    "        logreg = LogisticRegression()\n",
    "        logreg.fit(X_train, y_train)\n",
    "        res.append((logreg.score(X_train, y_train),logreg.score(X_test, y_test)));\n",
    "    random_score.append((np.mean([x[0] for x in res]),np.mean([x[1] for x in res])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(121)\n",
    "plt.plot([x[0] for x in real_score])\n",
    "plt.plot([x[0] for x in random_score],'k')\n",
    "plt.ylim(0,1)\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.plot([x[1] for x in real_score])\n",
    "plt.plot([x[1] for x in random_score],'k')\n",
    "plt.ylim(0,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises \n",
    "- can you classify states instead of diseases?\n",
    "- where do classically interesting features lie?\n",
    "- etc \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
